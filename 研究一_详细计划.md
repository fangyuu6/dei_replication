# 研究一：构建美味效率指数（DEI）——零预算详细执行计划

> **核心目标**：利用公开数据和开源工具，构建首个将食物好吃程度与环境代价配对的大规模数据库，计算并验证 DEI 指标。
>
> **约束条件**：零预算、个人或小团队可执行、依赖公开数据和开源工具。

---

## 0. 总览：做什么、怎么做、需要什么

### 最终产出

一个包含 **5,000–50,000 道菜品**的数据库，每道菜品包含：

| 字段 | 来源 | 说明 |
|------|------|------|
| 菜品名称 | 平台数据 | 标准化后的菜名 |
| 菜系分类 | 平台数据 + 规则 | 中餐/日料/西餐/... |
| 享乐评分 H | NLP 提取 | 从评论文本中提取的"好吃程度"分数 |
| 碳足迹 E_carbon | 食材配方 × 排放因子 | kg CO₂eq / 份 |
| 水足迹 E_water | 食材配方 × 水足迹因子 | L / 份 |
| 能耗估算 E_energy | 烹饪方式 × 能耗系数 | kWh / 份 |
| 废弃物估算 E_waste | 食材损耗率 + 包装 | kg / 份 |
| 综合环境代价 E | 标准化加权合成 | 无量纲 |
| **DEI = H / E** | 计算 | **核心指标** |

### 技术栈

```
数据采集：Python (requests, BeautifulSoup/Selenium, API)
NLP 模型：HuggingFace Transformers (开源, 免费)
环境数据：Agribalyse 3.1 (开源) + USDA FoodData Central (免费)
计算框架：pandas, numpy, scikit-learn
可视化：matplotlib, seaborn, plotly
存储：SQLite / CSV（无需服务器）
GPU（如需微调）：Google Colab 免费版 / Kaggle Notebooks
```

### 时间线：16 周

```
周 1-2    周 3-5    周 6-8    周 9-11   周 12-13  周 14-16
──────    ──────    ──────    ──────    ──────    ──────
数据源     平台数据   NLP模型   环境数据   DEI计算   验证与
调研与     采集与     训练与    匹配与     与分析    论文
准备工作   清洗       部署     估算                 初稿
```

---

## 1. 第一阶段：数据源调研与准备（第 1–2 周）

### 1.1 确定数据平台

**优先级排序**（基于数据可获取性和研究价值）：

| 平台 | 语言 | 菜品级评论 | 获取难度 | 优先级 | 说明 |
|------|------|-----------|---------|-------|------|
| **大众点评** | 中文 | ✅ 有菜品推荐功能 | 高（反爬严格） | ⭐⭐⭐ | 中餐最丰富的菜品级数据 |
| **Google Maps Reviews** | 多语言 | ❌ 餐厅级 | 中 | ⭐⭐ | 覆盖面广 |
| **Yelp** | 英文 | ❌ 餐厅级（文本中提及菜品） | 中（有部分 API） | ⭐⭐ | 美国数据丰富 |
| **Tabelog** | 日文 | ✅ 有菜品评分 | 高 | ⭐⭐ | 日料数据 |
| **小红书** | 中文 | ✅ 菜品级笔记 | 高 | ⭐ | 年轻消费者视角 |
| **美团** | 中文 | ✅ 菜品评论 | 很高 | ⭐ | 外卖场景数据 |
| **TripAdvisor** | 多语言 | ❌ 餐厅级 | 中低 | ⭐⭐ | 国际化数据 |

**务实建议**：先从数据最容易获取的平台开始，逐步扩展。

### 1.2 替代数据源（更容易获取）

由于主流平台反爬机制严格，以下替代数据源可能更实际：

| 数据源 | 类型 | 获取方式 | 数据量 |
|-------|------|---------|-------|
| **Kaggle 公开数据集** | 已爬取的餐厅评论 | 直接下载 | 数十万条 |
| **Yelp Open Dataset** | 官方公开的评论数据 | 申请下载 | 约 700 万条评论 |
| **Amazon Fine Food Reviews** | 食品评论 | Kaggle | 50 万+ 条 |
| **Google Local Reviews (开放数据集)** | 餐厅评论 | 学术申请 | 视数据集 |
| **学术论文附带数据** | 感官评价数据 | 论文补充材料 | 数百至数千 |
| **食谱网站**（下厨房、AllRecipes） | 菜谱 + 用户评分 | API 或爬取 | 数万道菜 |

**⭐ 首选方案**：**Yelp Open Dataset** — 官方提供，无版权问题，包含评论文本和评分，可直接用于研究。

### 1.3 操作步骤

```
□ 1. 下载 Yelp Open Dataset
     https://www.yelp.com/dataset
     注册学术用途，下载 JSON 数据
     包含：business.json, review.json, user.json

□ 2. 探索数据结构
     - 多少餐饮类 business？
     - 评论中是否提及具体菜品？
     - 星级分布如何？

□ 3. （可选）爬取补充数据
     - 下厨房（xiachufang.com）：中文菜谱 + 评分
     - AllRecipes：英文菜谱 + 评分
     重点获取：菜名、食材列表、用户评分、评论文本

□ 4. 建立食谱数据库（用于环境代价计算）
     来源：
     - 下厨房 / AllRecipes（菜名→食材清单）
     - Recipe1M+ 数据集（MIT 开源，100万+菜谱）
     目标：每道菜品 → 食材清单 + 各食材用量
```

---

## 2. 第二阶段：平台数据采集与清洗（第 3–5 周）

### 2.1 Yelp Open Dataset 处理

#### 2.1.1 数据加载与筛选

```python
# 伪代码 — 实际脚本将在执行时编写
import pandas as pd
import json

# 加载 business 数据，筛选餐饮类
businesses = pd.read_json('yelp_academic_dataset_business.json', lines=True)
restaurants = businesses[businesses['categories'].str.contains('Restaurant|Food', na=False)]

# 按菜系分类
cuisine_keywords = {
    'Chinese': ['Chinese', 'Dim Sum', 'Szechuan', 'Cantonese', 'Hunan'],
    'Japanese': ['Japanese', 'Sushi', 'Ramen', 'Izakaya'],
    'Italian': ['Italian', 'Pizza', 'Pasta'],
    'Mexican': ['Mexican', 'Tacos', 'Burrito'],
    'Indian': ['Indian', 'Curry', 'Tandoori'],
    'French': ['French', 'Bistro', 'Brasserie'],
    'American': ['American', 'Burger', 'BBQ', 'Steakhouse'],
    'Thai': ['Thai'],
    'Korean': ['Korean', 'BBQ'],
    'Mediterranean': ['Mediterranean', 'Greek', 'Turkish'],
}

# 加载对应评论
reviews = pd.read_json('yelp_academic_dataset_review.json', lines=True)
restaurant_reviews = reviews[reviews['business_id'].isin(restaurants['business_id'])]
```

#### 2.1.2 从评论文本中提取菜品提及

这是关键的一步——Yelp 评论是餐厅级的，我们需要把它降维到**菜品级**。

```python
# 策略：从评论中识别具体菜品名称
# 步骤 1：构建菜品词典（从菜谱数据库）
# 步骤 2：在评论文本中匹配菜品名称
# 步骤 3：提取该菜品周围的句子，判断情感

# 示例：
# 评论文本："The pad thai was incredible, best I've ever had. 
#           But the spring rolls were soggy and bland."
# 提取：
#   pad thai → 正面情感 → H = 高
#   spring rolls → 负面情感 → H = 低
```

**具体实现方案**：

```
方案 A（简单）：关键词匹配 + 规则情感分析
  - 菜品词典匹配（精确 + 模糊）
  - 菜品名周围 ±2 句的情感分析
  - 优点：简单，无需标注数据
  - 缺点：召回率有限

方案 B（推荐）：LLM 零样本提取
  - 用开源 LLM（如 Llama 3, Qwen）做零样本信息提取
  - Prompt: "从以下评论中提取提到的每道菜品名称及其好吃程度评价（1-10分）"
  - 优点：准确度高，能处理复杂表达
  - 缺点：需要 GPU 或 API 调用

方案 C（高精度）：微调专用模型
  - 人工标注 500-1000 条评论作为训练集
  - 微调 BERT/RoBERTa 做菜品实体识别 + 情感分析
  - 优点：最高精度
  - 缺点：需要标注工作量
```

**推荐策略**：先用方案 B（LLM 零样本）处理全量数据，再用方案 C（微调模型）对子集做高精度验证。

#### 2.1.3 数据清洗规则

```
□ 去重：同一用户对同一餐厅的重复评论
□ 筛选：评论长度 ≥ 20 词（过短的无法提取菜品信息）
□ 语言检测：确保评论语言与预期匹配
□ 菜品标准化：
  - "宫保鸡丁" = "Kung Pao Chicken" = "kung pao" → 统一编码
  - 建立菜品同义词表
□ 异常值处理：
  - 评分全 5 星或全 1 星的用户（可能是刷单/黑评）
  - 餐厅粉丝/竞争对手的极端评论
□ 最少评论数阈值：每道菜品至少 10 条独立评论
```

### 2.2 下厨房 / AllRecipes 菜谱数据

**目标**：获取"菜品名 → 食材清单 + 用量"的映射，用于计算环境代价。

```
□ 数据字段：
  - 菜品名称（中/英文）
  - 食材列表 + 每种食材用量（克）
  - 烹饪方式（炒/蒸/煮/烤/炸/...）
  - 份数（几人份）
  - 用户评分
  - 烹饪时间

□ 处理：
  - 食材名标准化（如"鸡胸肉"→"chicken breast"→ Agribalyse ID）
  - 用量单位统一（全部转为克）
  - 按"每份"标准化
```

### 2.3 数据整合

最终形成的中间数据表：

```
dish_reviews 表：
┌──────────────┬────────────┬────────────┬───────────────┬──────────┐
│ dish_name    │ cuisine    │ review_text│ hedonic_score │ source   │
│ (标准化菜名) │ (菜系)     │ (评论原文) │ (1-10)        │ (yelp等) │
├──────────────┼────────────┼────────────┼───────────────┼──────────┤
│ kung_pao_chk │ Chinese    │ "The kung.."│ 8.2          │ yelp     │
│ pad_thai     │ Thai       │ "Really..."│ 7.5           │ yelp     │
│ ...          │ ...        │ ...        │ ...           │ ...      │
└──────────────┴────────────┴────────────┴───────────────┴──────────┘

dish_recipes 表：
┌──────────────┬─────────────────────────────────────────┬────────────┐
│ dish_name    │ ingredients (JSON)                       │ cook_method│
├──────────────┼─────────────────────────────────────────┼────────────┤
│ kung_pao_chk │ {"chicken_breast":250,"peanuts":50,...}  │ stir_fry   │
│ pad_thai     │ {"rice_noodle":200,"shrimp":100,...}     │ stir_fry   │
└──────────────┴─────────────────────────────────────────┴────────────┘
```

---

## 3. 第三阶段：NLP 模型——从评论中提取"好吃程度"（第 6–8 周）

### 3.1 任务定义

**输入**：一条餐厅评论文本
**输出**：该评论中提到的每道菜品及其好吃程度评分（1-10 分）

这是一个**方面级情感分析（Aspect-Based Sentiment Analysis, ABSA）**任务，其中"方面"是具体菜品名。

### 3.2 技术方案：分两步走

#### 第一步：菜品实体识别（Dish NER）

从评论中识别出所有提到的菜品名称。

```
方案 1：基于词典的匹配（快速基线）
  - 构建菜品词典（5,000-10,000 条常见菜品名）
  - 精确匹配 + 模糊匹配（Levenshtein 距离 ≤ 2）
  - 工具：flashtext / rapidfuzz (Python)
  
方案 2：开源 NER 模型（更准确）
  - 使用 SpaCy + 自定义训练数据
  - 或使用 HuggingFace 上的现有 food NER 模型
  - 如：Rosário/bert-base-NER-food (英文)

方案 3：LLM 零样本（最灵活）
  - Prompt: "列出这条评论中提到的所有具体菜品名称。"
  - 模型：Qwen2.5-7B / Llama-3-8B（本地运行）
  - 或通过免费 API 额度：Gemini API free tier / Groq free tier
```

#### 第二步：菜品级情感评分（Dish Sentiment Scoring）

对每道被提及的菜品，判断评论者觉得它有多好吃。

```
方案 1：基于规则的情感分析（快速基线）
  - 提取菜品名周围 ±2 句
  - 使用情感词典（如 AFINN, SentiWordNet）打分
  - 加权：考虑否定词、程度副词
  
方案 2：预训练情感模型（推荐平衡方案）
  - 使用 HuggingFace 上的食品领域情感模型
  - 如 nlptown/bert-base-multilingual-uncased-sentiment (1-5 星)
  - 映射到 1-10 分

方案 3：LLM 直接评分（最高精度，推荐）
  - 将菜品名和上下文句子输入 LLM
  - Prompt:
    "根据以下评论，这个人觉得 [菜品名] 有多好吃？
     请给出 1-10 分的评分和简要理由。
     1 = 非常难吃，5 = 一般，10 = 极其好吃。
     评论：[评论文本]
     菜品：[菜品名]
     评分："
  - 模型选择（零成本）：
    • Google AI Studio (Gemini 1.5 Flash): 免费额度 15 RPM
    • Groq (Llama 3): 免费额度
    • 本地部署 Qwen2.5-7B-Instruct（需 16GB+ 显存）
```

### 3.3 具体执行方案（推荐）

```
┌─────────────────────────────────────────────────────────────────┐
│ 推荐流水线：LLM 一步提取 + 小模型大规模处理                        │
│                                                                 │
│  1. 用 LLM（Gemini Flash 免费 API）处理 2,000 条评论             │
│     → 产出：菜品名 + 好吃程度评分（1-10）+ 理由                   │
│     → 作为标注数据集                                             │
│                                                                 │
│  2. 用这 2,000 条标注数据微调一个小模型                            │
│     → 模型：bert-base-multilingual 或 roberta-base              │
│     → 任务：输入(评论, 菜品名) → 输出(好吃程度 1-10)              │
│     → 在 Google Colab 免费 GPU 上训练                            │
│                                                                 │
│  3. 用微调后的小模型处理全量数据（数十万条评论）                     │
│     → 在 CPU 上即可运行，无需 GPU                                │
│     → 速度：约 50-100 条/秒                                     │
│                                                                 │
│  4. 质量验证：随机抽取 200 条，人工评分 vs. 模型评分               │
│     → 目标：Pearson r > 0.75, MAE < 1.0                        │
└─────────────────────────────────────────────────────────────────┘
```

### 3.4 享乐评分聚合

```python
# 对每道菜品，聚合所有评论的好吃程度评分

dish_hedonic = (
    dish_reviews
    .groupby('dish_name_standardized')
    .agg(
        H_mean=('hedonic_score', 'mean'),       # 均值 → 作为 H
        H_median=('hedonic_score', 'median'),    # 中位数 → 稳健性检验
        H_std=('hedonic_score', 'std'),          # 标准差 → 一致性
        H_n=('hedonic_score', 'count'),          # 评论数 → 可靠性
        H_ci95=('hedonic_score', lambda x: 1.96 * x.std() / (len(x)**0.5)),  # 95% CI
    )
    .query('H_n >= 10')  # 至少 10 条评论才纳入
)
```

---

## 4. 第四阶段：环境代价计算（第 9–11 周）

### 4.1 数据源

**全部免费、公开：**

| 数据库 | 内容 | 获取方式 | 格式 |
|-------|------|---------|------|
| **Agribalyse 3.1** | 法国国家 LCA 数据库，覆盖 2,500+ 农食产品的碳足迹、水足迹、土地使用等 | https://agribalyse.ademe.fr/ 免费下载 | CSV/JSON |
| **USDA FoodData Central** | 美国农业部食物成分数据库，每种食材的营养成分和重量 | https://fdc.nal.usda.gov/ API 免费 | JSON API |
| **Water Footprint Network** | 各类食材的水足迹数据（绿水/蓝水/灰水） | https://www.waterfootprint.org/publications/ | PDF/Excel |
| **Poore & Nemecek 2018 补充数据** | Science 论文附带的全球食物 LCA 数据 | 论文 Supplementary Materials | Excel |
| **Our World in Data** | 食物碳足迹可视化数据 | https://ourworldindata.org/food-choice-vs-eating-local | CSV |

### 4.2 食材 → 环境影响因子映射

构建一个"食材环境影响因子表"：

```
ingredient_impact 表：
┌──────────────────┬──────────────┬──────────────┬──────────────┐
│ ingredient       │ co2_per_kg   │ water_per_kg │ land_per_kg  │
│ (食材标准名)     │ (kg CO₂eq)   │ (L)          │ (m²)         │
├──────────────────┼──────────────┼──────────────┼──────────────┤
│ beef             │ 60.0         │ 15,415       │ 326.0        │
│ chicken          │ 6.9          │ 4,325        │ 12.2         │
│ tofu             │ 3.2          │ 2,523        │ 2.2          │
│ rice             │ 4.5          │ 2,500        │ 2.8          │
│ potato           │ 0.5          │ 287          │ 0.9          │
│ tomato           │ 2.1          │ 214          │ 0.8          │
│ olive_oil        │ 6.0          │ 14,430       │ 26.3         │
│ ...              │ ...          │ ...          │ ...          │
└──────────────────┴──────────────┴──────────────┴──────────────┘
```

**来源优先级**：Agribalyse 3.1 > Poore & Nemecek > Water Footprint Network > Our World in Data

### 4.3 每道菜的环境代价计算

```python
def compute_dish_env_cost(dish_recipe, ingredient_impacts, cooking_method_energy):
    """
    计算一道菜每份的环境代价。
    
    dish_recipe: dict, 如 {"chicken_breast": 250, "peanuts": 50, "soy_sauce": 30}
                 单位：克
    ingredient_impacts: DataFrame, 食材环境影响因子表
    cooking_method_energy: dict, 烹饪方式 → kWh/份
    """
    
    # 1. 食材碳足迹
    co2_total = 0
    water_total = 0
    for ingredient, grams in dish_recipe['ingredients'].items():
        kg = grams / 1000
        impact = ingredient_impacts.loc[ingredient]
        co2_total += kg * impact['co2_per_kg']
        water_total += kg * impact['water_per_kg']
    
    # 2. 烹饪能耗（估算）
    cooking_energy = cooking_method_energy.get(dish_recipe['cook_method'], 0.5)
    # 将 kWh 转化为 CO₂：以全球平均电网排放因子 0.475 kg CO₂/kWh
    co2_cooking = cooking_energy * 0.475
    
    # 3. 清洗开销（基于餐具数量的估算）
    # 保守估算：每个餐具清洗消耗 0.5L 水 + 0.01 kWh
    vessel_count = dish_recipe.get('vessel_count', 2)  # 默认 2 个（碗+盘）
    water_cleaning = vessel_count * 0.5
    co2_cleaning = vessel_count * 0.01 * 0.475
    
    # 4. 综合
    E_carbon = co2_total + co2_cooking + co2_cleaning  # kg CO₂eq
    E_water = water_total + water_cleaning              # L
    E_energy = cooking_energy                           # kWh
    
    return {
        'E_carbon': E_carbon,
        'E_water': E_water, 
        'E_energy': E_energy,
    }
```

### 4.4 烹饪方式能耗系数

| 烹饪方式 | 估算能耗 (kWh/份) | 来源/依据 |
|---------|------------------|----------|
| 生食/凉拌 | 0.0 | 无需加热 |
| 蒸 | 0.3 | 蒸锅 15-30 min |
| 煮/汤 | 0.4 | 炉灶 20-40 min |
| 炒/煎 | 0.5 | 大火短时 5-15 min，但功率高 |
| 烤（烤箱） | 0.8 | 烤箱预热 + 烹饪 30-60 min |
| 炸 | 1.0 | 大量油加热 + 维持温度 |
| 慢炖 | 1.2 | 长时间低功率 |
| 烟熏 | 1.5 | 长时间 + 特殊设备 |

> 注：这些是粗略估算值。论文中需注明这是一阶近似，并在敏感性分析中测试 ±50% 的变化对结果的影响。

### 4.5 环境代价标准化与合成

```python
from sklearn.preprocessing import MinMaxScaler

# 标准化每个维度到 [0.01, 1]（避免除以 0）
scaler = MinMaxScaler(feature_range=(0.01, 1))

for col in ['E_carbon', 'E_water', 'E_energy']:
    dishes[col + '_norm'] = scaler.fit_transform(dishes[[col]])

# 加权合成 — 等权重作为基线
w_carbon = 1/3
w_water = 1/3
w_energy = 1/3

dishes['E_composite'] = (
    w_carbon * dishes['E_carbon_norm'] +
    w_water * dishes['E_water_norm'] +
    w_energy * dishes['E_energy_norm']
)
```

**加权方案的敏感性分析**：

| 方案名 | 碳权重 | 水权重 | 能耗权重 | 理由 |
|--------|-------|-------|---------|------|
| 等权重 | 1/3 | 1/3 | 1/3 | 基线/无先验 |
| 碳优先 | 0.5 | 0.25 | 0.25 | 气候变化优先 |
| 水优先 | 0.25 | 0.5 | 0.25 | 水资源稀缺地区 |
| ReCiPe 端点 | 按 ReCiPe 2016 | | | 学术标准 |

**在论文中报告所有方案的结果，证明核心结论对加权方式稳健。**

---

## 5. 第五阶段：DEI 计算与分析（第 12–13 周）

### 5.1 计算 DEI

```python
# 核心计算
dishes['DEI'] = dishes['H_mean'] / dishes['E_composite']

# DEI 分级（基于分位数）
dishes['DEI_tier'] = pd.qcut(dishes['DEI'], q=5, labels=['E','D','C','B','A'])
```

### 5.2 核心分析

#### 分析 1：全球 DEI 分布

```
□ DEI 的整体分布形态（直方图 + KDE）
□ 各菜系的 DEI 分布对比（箱线图 / 小提琴图）
□ H 与 E 的散点图（标注 DEI 等高线）
□ 帕累托前沿可视化
```

#### 分析 2：什么菜品 DEI 最高/最低？

```
□ 各菜系的 Top 10 / Bottom 10 DEI 菜品
□ DEI 与烹饪方式的关系
□ DEI 与食材数量的关系
□ DEI 与价格（如果有）的关系
□ DEI-A 菜品有什么共同特征？
```

#### 分析 3：效率前沿

```python
# 简化版 DEA：使用帕累托前沿
from scipy.spatial import ConvexHull

# 在 (E, H) 空间中，H 越高越好，E 越低越好
# 帕累托最优：不存在另一道菜同时更好吃且更环保
def is_pareto_optimal(costs):
    """costs 是 (n, 2) 数组，列 0 = E（越小越好），列 1 = -H（越小越好）"""
    is_efficient = np.ones(costs.shape[0], dtype=bool)
    for i, c in enumerate(costs):
        is_efficient[i] = np.all(np.any(costs[:i] > c, axis=1)) and \
                          np.all(np.any(costs[i+1:] > c, axis=1))
    return is_efficient

# 可视化：哪些菜品在前沿上，哪些远在前沿之内
```

#### 分析 4：菜系级别对比

```
□ 各菜系的平均 DEI 排名（但论文中强调菜系内变异大于菜系间差异）
□ 各菜系中前沿菜品的比例
□ 菜系内 DEI 方差分析 — 菜系内部差异有多大？
□ 回归分析：控制菜品类型后，菜系是否仍解释显著方差？
```

#### 分析 5："浪费空间"量化

**核心发现测试**：有多少菜品可以在不降低好吃程度的前提下减少环境代价？

```python
# 对于每道菜品，找到好吃程度相当但环境代价更低的"效率标杆"
for dish in dishes:
    # 找到 H ≥ dish.H * 0.95 且 E < dish.E 的菜品
    benchmarks = dishes[(dishes['H_mean'] >= dish['H_mean'] * 0.95) & 
                        (dishes['E_composite'] < dish['E_composite'])]
    if len(benchmarks) > 0:
        dish['E_reducible'] = dish['E_composite'] - benchmarks['E_composite'].min()
        dish['has_efficient_alternative'] = True

# 汇总："X% 的菜品存在同等好吃但环境代价更低的替代方案"
```

---

## 6. 第六阶段：验证与稳健性（第 14–16 周）

### 6.1 内部验证

| 验证项 | 方法 | 通过标准 |
|--------|------|---------|
| NLP 提取准确性 | 200 条人工标注 vs. 模型评分 | Pearson r > 0.75, MAE < 1.0 |
| 享乐评分信度 | 同一道菜不同评论者间的 ICC | ICC > 0.60 |
| 食材配方准确性 | 50 道菜的菜谱交叉验证（2+ 来源） | 食材列表重叠率 > 80% |
| DEI 对加权方案稳健 | 4 种加权方案的 DEI 排名相关性 | Spearman ρ > 0.85 |

### 6.2 外部验证

| 验证项 | 方法 | 预期结果 |
|--------|------|---------|
| DEI 与平台评分（Yelp 星级）的关系 | 相关分析 | 正相关但 r < 0.5（DEI ≠ 星级） |
| DEI 与营养评分的关系 | 相关分析 | 低相关（r < 0.3），证明 DEI 提供新信息 |
| DEI-A 菜品 vs. DEI-E 菜品的感知差异 | 招募 20-30 人做小规模盲测 | DEI-A 菜品好吃+环保，DEI-E 反之 |
| 专家面效度检验 | 邀请 5-10 位厨师/餐饮专家审阅 DEI 排名 | 专家认可大多数排名"合理" |

### 6.3 敏感性分析清单

```
□ 改变 E 的加权方案（4 种） → DEI 排名变化多大？
□ 改变享乐评分最低评论数阈值（10, 20, 30, 50） → 结果变化？
□ 排除评论数最多和最少的 5% 菜品 → 分布变化？
□ 仅使用碳足迹 vs. 综合 E → 结论一致？
□ 用中位数代替均值作为 H → 结论变化？
□ 改变食材用量 ±20% → DEI 变化幅度？
□ 不同 NLP 模型（规则 vs. 微调 vs. LLM） → 享乐评分一致性？
```

---

## 7. 产出与成果

### 7.1 数据库（开源发布）

```
DEI_database_v1/
├── data/
│   ├── dish_hedonic_scores.csv        # 每道菜的享乐评分
│   ├── dish_environmental_costs.csv   # 每道菜的环境代价
│   ├── dish_DEI_scores.csv            # 每道菜的 DEI 及分级
│   ├── ingredient_impact_factors.csv  # 食材环境影响因子表
│   └── cooking_method_energy.csv      # 烹饪方式能耗系数
├── models/
│   ├── dish_ner_model/                # 菜品实体识别模型
│   └── hedonic_scorer_model/          # 好吃程度评分模型
├── code/
│   ├── 01_data_collection.py
│   ├── 02_nlp_extraction.py
│   ├── 03_env_cost_calculation.py
│   ├── 04_dei_computation.py
│   ├── 05_analysis.py
│   └── 06_validation.py
├── results/
│   ├── figures/                       # 论文图表
│   └── tables/                        # 论文表格
└── README.md
```

### 7.2 论文图表规划

| 图/表编号 | 内容 | 类型 |
|----------|------|------|
| **Fig 1** | DEI 概念框架示意图（H / E 的来源，如何计算） | 概念图 |
| **Fig 2** | H vs. E 散点图，颜色标注菜系，叠加帕累托前沿线 | 散点图 |
| **Fig 3** | 各菜系 DEI 分布对比（小提琴图或蜂群图） | 分布图 |
| **Fig 4** | "浪费空间"可视化：每道菜与其最近前沿菜品的距离 | 改良散点图 |
| **Fig 5** | DEI 对加权方案的敏感性分析（平行坐标图） | 稳健性图 |
| **Table 1** | 各菜系 Top 5 / Bottom 5 DEI 菜品 | 表格 |
| **Table 2** | DEI 决定因素的回归结果 | 回归表 |
| **Table 3** | 各验证指标汇总 | 验证表 |
| **Extended Data** | 完整菜品 DEI 排名、额外稳健性检验 | 补充材料 |

---

## 8. 局限性（论文中必须讨论）

| 局限 | 说明 | 缓解 |
|------|------|------|
| **享乐评分来自平台评论而非受控品评** | 混杂了服务、环境、价格等因素 | NLP 模型专门提取食物好吃程度；报告验证指标 |
| **食材配方基于菜谱网站而非餐厅实际用量** | 餐厅可能调整配方 | 使用多来源菜谱取均值；敏感性分析 ±20% |
| **环境代价是估算值而非实测** | 没有分项计量实测数据 | 使用经过同行评审的 LCA 数据库（Agribalyse）；标注所有估算环节 |
| **样本偏向大众平台上有评论的菜品** | 遗漏了不上网的传统小店 | 承认这一局限；讨论对结果代表性的影响 |
| **跨菜系对比有文化偏差** | 不同文化的评论风格不同 | 重点报告菜系内对比；谨慎讨论跨菜系结论 |
| **清洗和包装的环境代价高度简化** | 仅用餐具数量粗略估算 | 标注为一阶近似；作为未来实测研究的动机 |

---

## 9. 每周执行检查表

### 第 1 周
```
□ 下载 Yelp Open Dataset
□ 下载 Agribalyse 3.1 数据库
□ 下载 Poore & Nemecek 2018 补充数据
□ 搭建 Python 开发环境（pandas, transformers, etc.）
□ 探索 Yelp 数据结构，统计餐饮类 business 数量和评论数量
□ 初步评估：数据中有多少评论提到了具体菜品？
```

### 第 2 周
```
□ 构建菜品词典（英文 5,000+ 条目）
  来源：AllRecipes 菜名 + Yelp 高频提及
□ 开始爬取 AllRecipes 或下载 Recipe1M+ 数据集
□ 建立食材标准化映射表（菜谱食材名 → Agribalyse ID）
□ 注册 Gemini API / Groq API（免费额度）
```

### 第 3–4 周
```
□ Yelp 评论筛选：餐饮类 + 英文 + 长度 ≥ 20 词
□ 菜品词典匹配：从评论中识别菜品提及
□ 统计：多少评论包含可识别的菜品名？覆盖多少独立菜品？
□ 开始用 LLM API 标注 2,000 条评论
  每条输出：[菜品名, 好吃程度 1-10, 依据]
□ 质量抽查：人工审阅 100 条 LLM 标注，记录准确率
```

### 第 5 周
```
□ 完成 2,000 条标注数据集
□ 完成菜谱数据库：≥ 3,000 道菜品的食材列表 + 用量
□ 食材标准化映射完成率 > 90%
□ 数据清洗定稿：去重、异常值处理、最低评论数阈值
```

### 第 6–7 周
```
□ 在 Google Colab 上微调 BERT/RoBERTa
  输入：(评论文本, 菜品名)
  输出：好吃程度 1-10
□ 评估：验证集 Pearson r, MAE, 混淆矩阵
□ 如果性能不足 → 增加标注数据至 3,000-5,000 条
□ 用微调模型处理全量评论数据
```

### 第 8 周
```
□ 200 条人工验证（自己 + 找 1-2 位朋友帮忙）
□ 计算 NLP 验证指标
□ 聚合：每道菜品的 H_mean, H_std, H_n
□ 筛选：H_n ≥ 10 的菜品纳入分析
□ 中期数据汇总：覆盖了多少菜品？多少菜系？
```

### 第 9–10 周
```
□ 构建 ingredient_impact 表：覆盖数据库中 95%+ 的食材
□ 匹配：菜谱食材 → 环境影响因子
□ 计算：每道菜的 E_carbon, E_water, E_energy
□ 估算缺失食材的影响因子（取类似食材均值）
□ 赋予每道菜烹饪方式分类
```

### 第 11 周
```
□ E 标准化 + 加权合成（4 种方案）
□ DEI = H / E 计算
□ DEI 分级
□ 基础可视化：分布、散点、箱线图
```

### 第 12–13 周
```
□ 完整分析：5 项核心分析 + 图表制作
□ 帕累托前沿分析
□ "浪费空间"量化
□ 回归分析：DEI 的决定因素
```

### 第 14–15 周
```
□ 敏感性分析（7 项）
□ 外部验证
□ 如可能：小规模盲测验证（20-30 人）
```

### 第 16 周
```
□ 论文初稿撰写
□ 图表定稿
□ 开源代码和数据整理
□ README 撰写
```

---

## 10. 所需资源清单（零成本）

| 资源 | 用途 | 获取 |
|------|------|------|
| Yelp Open Dataset | 评论数据 | 免费申请下载 |
| Recipe1M+ | 菜谱数据 | MIT 开源 |
| Agribalyse 3.1 | 食材 LCA 数据 | 免费下载 |
| USDA FoodData Central | 食物成分 | 免费 API |
| Water Footprint Network | 水足迹数据 | 部分免费 |
| Poore & Nemecek 2018 数据 | 全球食物 LCA | 论文补充材料 |
| Google Colab | GPU 训练 | 免费版 |
| HuggingFace Transformers | NLP 模型 | 开源 |
| Gemini API (Free tier) | LLM 标注 | 15 RPM 免费 |
| Python + 开源库 | 全部代码 | 免费 |

**总计预算：$0**

---

*研究一详细执行计划 v1.0*
*创建时间：2026-02-23*
*预计执行周期：16 周*
